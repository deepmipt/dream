services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.channel=telegram agent.telegram_token=$TG_TOKEN agent.pipeline_config=assistant_dists/dream_multimodal/pipeline_conf.json agent.db_config=assistant_dists/dream_multimodal/db_conf.json'
    environment:
      WAIT_HOSTS: "dff-program-y-skill:8008, sentseg:8011, ranking-based-response-selector:8002,
          prompt-selector:8135, intent-catcher:8019,
          dff-intent-responder-skill:8012,
          sentence-ranker:8128, german-translation-pa:8181,
          vidchapters-service:8045, dff-vidchapters-skill:8046,
          fromage:8069, dff-fromage-image-skill:8070"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-1200}
      HIGH_PRIORITY_INTENTS: 1
      RESTRICTION_FOR_SENSITIVE_CASE: 1
      ALWAYS_TURN_ON_ALL_SKILLS: 0
      LANGUAGE: EN
      FALLBACK_FILE: fallbacks_dream_en.json

  files:
    image: julienmeerschart/simple-file-upload-download-server

  ranking-based-response-selector:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8002
        SERVICE_NAME: response_selector
        LANGUAGE: EN
        SENTENCE_RANKER_ANNOTATION_NAME: sentence_ranker
        SENTENCE_RANKER_SERVICE_URL: http://sentence-ranker:8128/respond
        SENTENCE_RANKER_TIMEOUT: 3
        N_UTTERANCES_CONTEXT: 5
        FILTER_TOXIC_OR_BADLISTED: 1
        FALLBACK_FILE: fallbacks_dream_en.json
      context: .
      dockerfile: ./response_selectors/ranking_based_response_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8002
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  sentseg:
    env_file: [ .env ]
    build:
      context: ./annotators/SentSeg/
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1.5G

  dff-program-y-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8008
        SERVICE_NAME: dff_program_y_skill
        LANGUAGE: EN
      context: .
      dockerfile: ./skills/dff_program_y_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8008 --reload
    deploy:
      resources:
        limits:
          memory: 1024M
        reservations:
          memory: 1024M

  dff-intent-responder-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8012
        SERVICE_NAME: dff_intent_responder_skill
        INTENT_RESPONSE_PHRASES_FNAME: intent_response_phrases.json
      context: .
      dockerfile: ./skills/dff_intent_responder_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8012 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M
  
  intent-catcher:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/IntentCatcherTransformers/Dockerfile
      args:
        SERVICE_PORT: 8019
        CONFIG_NAME: intents_model_dp_config.json
        INTENT_PHRASES_PATH: intent_phrases.json
    command: python -m flask run -h 0.0.0.0 -p 8019
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES={device_id}
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  prompt-selector:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8135
        SERVICE_NAME: prompt_selector
        SENTENCE_RANKER_SERVICE_URL: http://sentence-ranker:8128/respond
        N_SENTENCES_TO_RETURN: 3
        PROMPTS_TO_CONSIDER: dream_persona,dream_faq
      context: .
      dockerfile: ./annotators/prompt_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8135
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  sentence-ranker:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8128
        SERVICE_NAME: sentence_ranker
        PRETRAINED_MODEL_NAME_OR_PATH: sentence-transformers/all-MiniLM-L6-v2
      context: ./services/sentence_ranker/
    command: flask run -h 0.0.0.0 -p 8128
    environment:
      - CUDA_VISIBLE_DEVICES={device_id}
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G
  
  vidchapters-service:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8045
        SERVICE_NAME: vidchapters_service
      context: .
      dockerfile: ./annotators/vidchapters_service/Dockerfile
    command: uvicorn server:app --host 0.0.0.0 --port 8045
    environment:
      - CUDA_VISIBLE_DEVICES={device_id}
    deploy:
      resources:
        limits:
          memory: 45G
        reservations:
          memory: 45G

  dff-vidchapters-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8046
        SERVICE_NAME: dff_vidchapters_skill
      context: .
      dockerfile: ./skills/dff_vidchapters_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8046 --reload
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M  

  fromage:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8069
        SERVICE_NAME: fromage
      context: .
      dockerfile: ./services/fromage/Dockerfile
    command: uvicorn server:app --host 0.0.0.0 --port 8069
    environment:
      - CUDA_VISIBLE_DEVICES={device_id}
    deploy:
      resources:
        limits:
          memory: 45G
        reservations:
          memory: 45G
          
  dff-fromage-image-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8070
        SERVICE_NAME: dff_fromage_image_skill
      context: .
      dockerfile: ./skills/dff_fromage_image_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8070 --reload
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  german-translation-pa:
    env_file: [ .env, .env_secret ]
    build:
      context: ./annotators/german_translation_pa/
    command: uvicorn server:app --host 0.0.0.0 --port 8181
    deploy:
      resources:
        limits:
          memory: 500M
        reservations:
          memory: 500M
version: '3.7'
