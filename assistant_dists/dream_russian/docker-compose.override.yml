services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.pipeline_config=assistant_dists/dream_russian/pipeline_conf.json'
    environment:
      WAIT_HOSTS: "dff-program-y-ru-skill:8008, convers-evaluation-selector-ru:8009, 
          dff-intent-responder-ru-skill:8012, intent-catcher-ru:8014, badlisted-words-ru:8018,
          ner-ru:8021, personal-info-ru-skill:8030, sentseg-ru:8011,
           spelling-preprocessing-ru:8074,
          dff-friendship-ru-skill:8086, entity-detection-ru:8103,
          dff-template-skill:8120, spacy-annotator-ru:8129, dff-generative-ru-skill:8092,
           text-qa-ru:8078, summarization-annotator:8058, rut5-summarizer:8060, combined-classification-ru:8198, gigachat-api:8187, dff-universal-prompted-skill:8147"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-1200}
      HIGH_PRIORITY_INTENTS: 1
      RESTRICTION_FOR_SENSITIVE_CASE: 1
      ALWAYS_TURN_ON_ALL_SKILLS: 0
      LANGUAGE: RU
      FALLBACK_FILE: fallbacks_dream_ru.json

  dff-program-y-ru-skill:
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8008
        SERVICE_NAME: dff_program_y_skill
        LANGUAGE: RU
      context: .
      dockerfile: ./skills/dff_program_y_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8008 --reload
    deploy:
      resources:
        limits:
          memory: 1024M
        reservations:
          memory: 1024M

  convers-evaluation-selector-ru:
    env_file: [ .env_ru ]
    build:
      args:
        TAG_BASED_SELECTION: 1
        CALL_BY_NAME_PROBABILITY: 0.5
        PROMPT_PROBA: 0.1
        ACKNOWLEDGEMENT_PROBA: 0.3
        PRIORITIZE_WITH_REQUIRED_ACT: 0
        PRIORITIZE_NO_DIALOG_BREAKDOWN: 0
        PRIORITIZE_WITH_SAME_TOPIC_ENTITY: 0
        IGNORE_DISLIKED_SKILLS: 0
        GREETING_FIRST: 1
        RESTRICTION_FOR_SENSITIVE_CASE: 1
        PRIORITIZE_PROMTS_WHEN_NO_SCRIPTS: 1
        MAX_TURNS_WITHOUT_SCRIPTS: 7
        ADD_ACKNOWLEDGMENTS_IF_POSSIBLE: 1
        PRIORITIZE_SCRIPTED_SKILLS: 0
        CONFIDENCE_STRENGTH: 0.8
        CONV_EVAL_STRENGTH: 0.4
        PRIORITIZE_HUMAN_INITIATIVE: 1
        QUESTION_TO_QUESTION_DOWNSCORE_COEF: 0.8
        LANGUAGE: RU
        FALLBACK_FILE: fallbacks_dream_ru.json
      context: .
      dockerfile: ./response_selectors/convers_evaluation_based_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8009
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dff-intent-responder-ru-skill:
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8012
        SERVICE_NAME: dff_intent_responder_skill
        INTENT_RESPONSE_PHRASES_FNAME: intent_response_phrases_RU.json
        LANGUAGE: RU
      context: .
      dockerfile: ./skills/dff_intent_responder_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8012 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  sentseg-ru:                 ##########
    env_file: [ .env_ru ]
    build:
      args:
        CONFIG: sentseg_ru_bert_torch.json
      context: ./annotators/sentseg_ru
      dockerfile: Dockerfile-test
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    # deploy:
    #   resources:
    #     limits:
    #       memory: 3G
    #     reservations:
    #       memory: 3G

  intent-catcher-ru:
    env_file: [ .env_ru ]
    build:
      context: .
      dockerfile: ./annotators/IntentCatcherTransformers/Dockerfile
      args:
        SERVICE_PORT: 8014
        CONFIG_NAME: intents_model_dp_config_RU.json
        INTENT_PHRASES_PATH: intent_phrases_RU.json
    command: python -m flask run -h 0.0.0.0 -p 8014
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  badlisted-words-ru:
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8018
        SERVICE_NAME: badlisted_words
      context: annotators/BadlistedWordsDetector_ru/
    command: flask run -h 0.0.0.0 -p 8018
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  combined-classification-ru: ################
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8198
        SERVICE_NAME: combined_classification_ru
        CONFIG: combined_classifier_ru.json
      context: .
      dockerfile: ./annotators/combined_classification_ru/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8198 --timeout 600
    environment:
      - CUDA_VISIBLE_DEVICES=0
    # deploy:
    #   resources:
    #     limits:
    #       memory: 2G
    #     reservations:
    #       memory: 2G
  ner-ru: #########################
    env_file: [ .env_ru ]
    build:
      args:
        CONFIG: ner_case_agnostic_multilingual_bert_base_extended.json
        SERVICE_PORT: 8021
        SRC_DIR: annotators/NER_deeppavlov
        COMMIT: f5117cd9ad1e64f6c2d970ecaa42fc09ccb23144
      context: ./
      dockerfile: annotators/NER_deeppavlov/Dockerfile
    command: flask run -h 0.0.0.0 -p 8021
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    tty: true
    # deploy:
    #   resources:
    #     limits:
    #       memory: 2G
    #     reservations:
    #       memory: 2G
  
  entity-detection-ru:  ############################
    env_file: [ .env_ru ]
    build:
      args:
        CONFIG: entity_detection_rus.json
        SERVICE_PORT: 8103
        SRC_DIR: annotators/entity_detection_rus
        LANGUAGE: RU
      context: ./
      dockerfile: annotators/entity_detection_rus/Dockerfile-test
    command: flask run -h 0.0.0.0 -p 8103
    environment:
      - FLASK_APP=server
    tty: true
    # deploy:
    #   resources:
    #     limits:
    #       memory: 3.5G
    #     reservations:
    #       memory: 3.5G

  personal-info-ru-skill:
    env_file: [ .env_ru ]
    build:
      context: .
      dockerfile: ./skills/personal_info_skill/Dockerfile
      args:
        LANGUAGE: RU
    command: flask run -h 0.0.0.0 -p 8030
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  spelling-preprocessing-ru:  ####################
    env_file: [ .env_ru ]
    build:
      args:
        CONFIG: levenshtein_corrector_ru.json
        SERVICE_PORT: 8074
        SRC_DIR: annotators/spelling_preprocessing_dp
        COMMIT: f5117cd9ad1e64f6c2d970ecaa42fc09ccb23144
        LANGUAGE: RU
      context: ./
      dockerfile: annotators/spelling_preprocessing_dp/Dockerfile
    command: flask run -h 0.0.0.0 -p 8074
    environment:
      - FLASK_APP=server
    # deploy:
    #   resources:
    #     limits:
    #       memory: 8G
    #     reservations:
    #       memory: 8G

  spacy-annotator-ru: ########################
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8129
        SRC_DIR: annotators/spacy_annotator
        SPACY_MODEL: ru_core_news_sm
        TOKEN_ATTRIBUTES: pos_|dep_|lemma_|ent_iob_|ent_type_|morph
        ANNOTATE_BATCH_WITH_TOKENS_ONLY: 1
      context: ./
      dockerfile: annotators/spacy_annotator/Dockerfile
    command: flask run -h 0.0.0.0 -p 8129
    environment:
      - FLASK_APP=server
    # deploy:
    #   resources:
    #     limits:
    #       memory: 256M
    #     reservations:
    #       memory: 256M

  dff-friendship-ru-skill:
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8086
        SERVICE_NAME: dff_friendship_skill
        LANGUAGE: RU
      context: .
      dockerfile: ./skills/dff_friendship_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8086
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-generative-ru-skill:
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8092
        SERVICE_NAME: dff_generative_skill
        LANGUAGE: RU
        GENERATIVE_SERVICE_URL: http://dialogpt-ru:8125/respond
      context: .
      dockerfile: ./skills/dff_generative_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8092 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-template-skill:
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8120
        SERVICE_NAME: dff_template_skill
      context: .
      dockerfile: ./skills/dff_template_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8120 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  text-qa-ru:
    env_file: [ .env_ru ]
    build:
      args:
        SERVICE_PORT: 8078
        SERVICE_NAME: text_qa
        CONFIG: qa_rus.json
      context: services/text_qa
      dockerfile: Dockerfile-test
    command: flask run -h 0.0.0.0 -p 8078
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
      - LANGUAGE=RU
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  summarization-annotator:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8058
        SERVICE_NAME: summarization_annotator
        SUMMARIZATION_REQUEST_TIMEOUT: 10
      context: ./annotators/summarization_annotator/
    command: flask run -h 0.0.0.0 -p 8058
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dff-universal-prompted-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8147
        SERVICE_NAME: dff_universal_prompted_skill
        GENERATIVE_TIMEOUT: 120
        N_UTTERANCES_CONTEXT: 7
        DEFAULT_LM_SERVICE_URL: http://gigachat-api:8187/respond
        DEFAULT_LM_SERVICE_CONFIG: default_generative_config.json
      context: .
      dockerfile: ./skills/dff_universal_prompted_skill/Dockerfile
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  rut5-summarizer:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8060
        SERVICE_NAME: ruT5_summarizer
        PRETRAINED_MODEL_NAME: "IlyaGusev/rut5_base_sum_gazeta"
      context: ./services/ruT5_summarizer/
    command: flask run -h 0.0.0.0 -p 8060
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 4G

version: '3.7'
