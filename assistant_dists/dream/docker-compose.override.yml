services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.pipeline_config=assistant_dists/dream/pipeline_conf.json'
    environment:
      WAIT_HOSTS: "convers-evaluator-annotator:8004,
          spacy-nounphrases:8006, rake-keywords:8007, dff-program-y-skill:8008, sentseg:8011, convers-evaluation-selector:8009,
          personality-catcher:8010, dff-intent-responder-skill:8012, intent-catcher:8014, badlisted-words:8018,
          sentrewrite:8017, ner:8021, dff-program-y-dangerous-skill:8022, dff-movie-skill:8023,
          convert-reddit:8029, personal-info-skill:8030, asr:8031, misheard-asr:8033, dff-weather-skill:8037,
          eliza:8047, emotion-skill:8049, dummy-skill-dialog:8052, comet-atomic:8053, meta-script-skill:8054,
          dff-coronavirus-skill:8061, small-talk-skill:8062, game-cooperative-skill:8068, dff-program-y-wide-skill:8064,
          comet-conceptnet:8065, news-api-skill:8066, dff-short-story-skill:8057, factoid-qa:8071, kbqa:8072,
          spelling-preprocessing:8074, entity-linking:8075, wiki-parser:8077, text-qa:8078,
          knowledge-grounding:8083, combined-classification:8087, knowledge-grounding-skill:8085,
          dff-friendship-skill:8086, entity-storer:8089,
          dff-book-skill:8032, dff-grounding-skill:8080,
          dff-animals-skill:8094, dff-travel-skill:8096, dff-food-skill:8097, dff-sport-skill:8098, dff-science-skill:8101,
          fact-random:8119, fact-retrieval:8100,
          dff-funfact-skill:8104, dff-bot-persona-skill:8105, news-api-annotator:8112,
          dff-gossip-skill:8109, dff-wiki-skill:8111, dff-gaming-skill:8115, topic-recommendation:8113,
          user-persona-extractor:8114, wiki-facts:8116, dff-music-skill:8099, entity-detection:8103, dff-art-skill:8117,
          midas-predictor:8121, dialogpt:8125, storygpt:8126, prompt-storygpt:8127, seq2seq-persona-based:8140, sentence-ranker:8128,
          property-extraction:8136, dff-template-skill:8120"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-480}
      HIGH_PRIORITY_INTENTS: 1
      RESTRICTION_FOR_SENSITIVE_CASE: 1
      ALWAYS_TURN_ON_ALL_SKILLS: 0
      LANGUAGE: EN

  sentseg:
    env_file: [ .env ]
    build:
      context: ./annotators/SentSeg/
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1.5G

  dff-intent-responder-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8012
        SERVICE_NAME: dff_intent_responder_skill
        INTENT_RESPONSE_PHRASES_FNAME: intent_response_phrases.json
      context: .
      dockerfile: ./skills/dff_intent_responder_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8012 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  intent-catcher:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/IntentCatcherTransformers/Dockerfile
      args:
        SERVICE_PORT: 8014
        CONFIG_NAME: intents_model_dp_config.json
        INTENT_PHRASES_PATH: intent_phrases.json
    command: python -m flask run -h 0.0.0.0 -p 8014
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  ner:
    env_file: [ .env ]
    build:
      args:
        CONFIG: ner_case_agnostic_multilingual_bert_base_extended.json
        SERVICE_PORT: 8021
        SRC_DIR: annotators/NER_deeppavlov
        COMMIT: f5117cd9ad1e64f6c2d970ecaa42fc09ccb23144
      context: ./
      dockerfile: annotators/NER_deeppavlov/Dockerfile
    command: flask run -h 0.0.0.0 -p 8021
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    tty: true
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  news-api-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8066
        SERVICE_NAME: news_api_skill
      context: .
      dockerfile: ./skills/news_api_skill/Dockerfile
    environment:
      - FLASK_APP=server
    command: flask run -h 0.0.0.0 -p 8066
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  news-api-annotator:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8112
        SERVICE_NAME: news_api_annotator
        ASYNC_SIZE: 3
      context: .
      dockerfile: ./annotators/news_api/Dockerfile
    environment:
      - FLASK_APP=server
    command: flask run -h 0.0.0.0 -p 8112
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  factoid-qa:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8071
        SERVICE_NAME: factoid_qa
      context: .
      dockerfile: ./skills/factoid_qa/Dockerfile
    command: flask run -h 0.0.0.0 -p 8071
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  entity-linking:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8075
        SERVICE_NAME: entity_linking
        CONFIG: entity_linking_eng.json
        SRC_DIR: annotators/entity_linking
      context: ./
      dockerfile: annotators/entity_linking/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 2.5G

  wiki-parser:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8077
        SERVICE_NAME: wiki_parser
        WIKI_LITE_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata2022.hdt
        WIKI_LITE_INDEX_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata2022.hdt.index.v1-1
        WIKI_CACHE_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata_cache.json
        CONFIG: wiki_parser.json
        SRC_DIR: annotators/wiki_parser
        COMMIT: ff5b156d16a949c3ec99da7fb60ae907dec37a41
        FAST: 1
      context: ./
      dockerfile: annotators/wiki_parser/Dockerfile
    command: flask run -h 0.0.0.0 -p 8077
    environment:
      - CUDA_VISIBLE_DEVICES=''
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  text-qa:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8078
        SERVICE_NAME: text_qa
        CONFIG: qa_eng.json
      context: services/text_qa
      dockerfile: Dockerfile
    command: flask run -h 0.0.0.0 -p 8078
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
      - LANGUAGE=EN
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  kbqa:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8072
        SERVICE_NAME: kbqa
        CONFIG: kbqa_cq_mt_bert_lite.json
        SRC_DIR: annotators/kbqa/
        COMMIT: 283a25e322e8fedc6ff0c159e4ec76bb165ae405
      context: ./
      dockerfile: annotators/kbqa/Dockerfile
    command: flask run -h 0.0.0.0 -p 8072
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 5G
        reservations:
          memory: 5G

  combined-classification:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8087
        SERVICE_NAME: combined_classification
        CONFIG: combined_classifier.json
      context: .
      dockerfile: ./annotators/combined_classification/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8087 --timeout 600
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  fact-retrieval:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8100
        SERVICE_NAME: fact_retrieval
        CONFIG: configs/fact_retrieval_page.json
        CONFIG_WIKI: configs/page_extractor.json
        CONFIG_WHOW: configs/whow_page_extractor.json
        SRC_DIR: annotators/fact_retrieval/
        COMMIT: 4b3e60c407644b750c9dc292ac6bf206081fb9d0
        N_FACTS: 3
      context: ./
      dockerfile: annotators/fact_retrieval/Dockerfile
    command: flask run -h 0.0.0.0 -p 8100
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 4G

  entity-detection:
    env_file: [ .env ]
    build:
      args:
        SERVICE_NAME: entity_detection
        SEQ_TAG_CONFIG: wikipedia_entity_detection_distilbert.json
        CONFIG: entity_detection_eng.json
        LOWERCASE: 1
        SERVICE_PORT: 8103
        SRC_DIR: annotators/entity_detection/
        FINEGRAINED: 0
      context: ./
      dockerfile: annotators/entity_detection/Dockerfile
    command: flask run -h 0.0.0.0 -p 8103
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 2.5G

  seq2seq-persona-based:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8140
        SERVICE_NAME: seq2seq_persona_based
        PRETRAINED_MODEL_NAME_OR_PATH: DeepPavlov/bart-base-en-persona-chat
        PAIR_DIALOG_HISTORY_LENGTH: 2
        CHAT_EVERY_SENT_MAX_LENGTH: 25
        PERSONA_EVERY_SENT_MAX_LENGTH: 19
        GENERATION_PARAMS_CONFIG: bart-base-en-persona-chat_v1.json
      context: .
      dockerfile: ./services/seq2seq_persona_based/Dockerfile
    command: flask run -h 0.0.0.0 -p 8140
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  relative-persona-extractor:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8133
        SERVICE_NAME: relative_persona_extractor
        N_SENTENCES_TO_RETURN: 3
      context: .
      dockerfile: ./annotators/relative_persona_extractor/Dockerfile
    command: flask run -h 0.0.0.0 -p 8133
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  sentence-ranker:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8128
        SERVICE_NAME: sentence_ranker
        PRETRAINED_MODEL_NAME_OR_PATH: sentence-transformers/all-MiniLM-L6-v2
      context: ./services/sentence_ranker/
    command: flask run -h 0.0.0.0 -p 8128
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  property-extraction:
    env_file: [.env]
    build:
      args:
        CONFIG: t5_generative_ie_lite_infer.json
        SERVICE_PORT: 8136
        SRC_DIR: annotators/property_extraction/
        SERVICE_NAME: property_extraction
      context: ./
      dockerfile: annotators/property_extraction/Dockerfile
    command: flask run -h 0.0.0.0 -p 8136
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 7G
        reservations:
          memory: 7G

version: '3.7'
