services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.pipeline_config=assistant_dists/dream/pipeline_conf.json'
    environment:
      WAIT_HOSTS: "convers-evaluator-annotator:8004,
          spacy-nounphrases:8006, rake-keywords:8007, dff-program-y-skill:8008, sentseg:8011, convers-evaluation-selector:8009,
          intent-catcher:8014, badlisted-words:8018,
          sentrewrite:8017, ner:8021, asr:8031, misheard-asr:8033, comet-atomic:8053,
          comet-conceptnet:8065, kbqa:8072,
          spelling-preprocessing:8074, entity-linking:8075, wiki-parser:8077, text-qa:8078,
          knowledge-grounding:8083, combined-classification:8087,
          dff-friendship-skill:8086, entity-storer:8089,
          fact-random:8119, fact-retrieval:8100, news-api-annotator:8112, topic-recommendation:8113,
          user-persona-extractor:8114, wiki-facts:8116, entity-detection:8103,
          midas-predictor:8121, sentence-ranker:8128, faq-skill:3772,
          dff-template-skill:8120"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-480}
      HIGH_PRIORITY_INTENTS: 1
      RESTRICTION_FOR_SENSITIVE_CASE: 1
      ALWAYS_TURN_ON_ALL_SKILLS: 0
      LANGUAGE: EN

  convers-evaluator-annotator:
    env_file: [ .env ]
    build:
      args:
        CONFIG: conveval.json
        PORT: 8004
        DATA_URL: https://files.deeppavlov.ai/alexaprize_data/cobot_conveval2.tar.gz
      context: .
      dockerfile: ./annotators/ConversationEvaluator/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  spacy-nounphrases:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/spacy_nounphrases/Dockerfile
    command: flask run -h 0.0.0.0 -p 8006
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  rake-keywords:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/rake_keywords/Dockerfile
    command: flask run -h 0.0.0.0 -p 8007
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dff-program-y-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8008
        SERVICE_NAME: dff_program_y_skill
        LANGUAGE: EN
      context: .
      dockerfile: ./skills/dff_program_y_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8008 --reload
    deploy:
      resources:
        limits:
          memory: 1024M
        reservations:
          memory: 1024M

  sentseg:
    env_file: [ .env ]
    build:
      context: ./annotators/SentSeg/
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1.5G

  convers-evaluation-selector:
    env_file: [ .env ]
    build:
      args:
        TAG_BASED_SELECTION: 1
        CALL_BY_NAME_PROBABILITY: 0.5
        PROMPT_PROBA: 0.1
        ACKNOWLEDGEMENT_PROBA: 0.3
        PRIORITIZE_WITH_REQUIRED_ACT: 0
        PRIORITIZE_NO_DIALOG_BREAKDOWN: 0
        PRIORITIZE_WITH_SAME_TOPIC_ENTITY: 0
        IGNORE_DISLIKED_SKILLS: 0
        GREETING_FIRST: 1
        RESTRICTION_FOR_SENSITIVE_CASE: 1
        PRIORITIZE_PROMTS_WHEN_NO_SCRIPTS: 1
        MAX_TURNS_WITHOUT_SCRIPTS: 7
        ADD_ACKNOWLEDGMENTS_IF_POSSIBLE: 1
        PRIORITIZE_SCRIPTED_SKILLS: 0
        CONFIDENCE_STRENGTH: 0.8
        CONV_EVAL_STRENGTH: 0.4
        PRIORITIZE_HUMAN_INITIATIVE: 1
        QUESTION_TO_QUESTION_DOWNSCORE_COEF: 0.8
      context: .
      dockerfile: ./response_selectors/convers_evaluation_based_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8009
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  sentrewrite:
    env_file: [ .env ]
    build:
      context: ./annotators/SentRewrite/
    command: flask run -h 0.0.0.0 -p 8017
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 512M

  intent-catcher:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/IntentCatcherTransformers/Dockerfile
      args:
        SERVICE_PORT: 8014
        CONFIG_NAME: intents_model_dp_config.json
        INTENT_PHRASES_PATH: intent_phrases.json
    command: python -m flask run -h 0.0.0.0 -p 8014
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  badlisted-words:
    env_file: [ .env ]
    build:
      context: annotators/BadlistedWordsDetector/
    command: flask run -h 0.0.0.0 -p 8018
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  ner:
    env_file: [ .env ]
    build:
      args:
        CONFIG: ner_case_agnostic_multilingual_bert_base_extended.json
        PORT: 8021
        SRC_DIR: annotators/NER_deeppavlov
        COMMIT: f5117cd9ad1e64f6c2d970ecaa42fc09ccb23144
      context: ./
      dockerfile: annotators/NER_deeppavlov/Dockerfile
    command: flask run -h 0.0.0.0 -p 8021
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    tty: true
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  asr:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/asr/Dockerfile
    command: flask run -h 0.0.0.0 -p 8031
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 80M
        reservations:
          memory: 80M

  comet-atomic:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/COMeT/Dockerfile
      args:
        GRAPH: atomic
        SERVICE_HOME: ./annotators/COMeT
        SERVICE_NAME: comet_atomic
        SERVICE_PORT: 8053
        PRETRAINED_MODEL: http://lnsigo.mipt.ru/export/alexaprize_data/comet/atomic_pretrained_model.pickle
        PREPROCESS_DATA: "http://lnsigo.mipt.ru/export/alexaprize_data/comet/categories_oEffect%23oReact%23oWant%23xAttr%23xEffect%23xIntent%23xNeed%23xReact%23xWant-maxe1_17-maxe2_35-maxr_1.pickle"
        DECODING_ALGO: beam-3
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  comet-conceptnet:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/COMeT/Dockerfile
      args:
        GRAPH: conceptnet
        SERVICE_HOME: ./annotators/COMeT/
        SERVICE_NAME: comet_conceptnet
        SERVICE_PORT: 8065
        PRETRAINED_MODEL: http://lnsigo.mipt.ru/export/alexaprize_data/conceptnet/conceptnet_pretrained_model.pickle
        PREPROCESS_DATA: http://lnsigo.mipt.ru/export/alexaprize_data/conceptnet/rel_language-trainsize_100-devversion_12-maxe1_10-maxe2_15-maxr_5.pickle
        DECODING_ALGO: beam-3
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  news-api-annotator:
    env_file: [ .env ]
    build:
      args:
        ASYNC_SIZE: 3
      context: .
      dockerfile: ./annotators/news_api/Dockerfile
    environment:
      - FLASK_APP=server
    command: flask run -h 0.0.0.0 -p 8112
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  entity-linking:
    env_file: [ .env ]
    build:
      args:
        CONFIG: entity_linking_eng.json
        PORT: 8075
        SRC_DIR: annotators/entity_linking
      context: ./
      dockerfile: annotators/entity_linking/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 23G
        reservations:
          memory: 23G

  wiki-parser:
    env_file: [ .env ]
    build:
      args:
        WIKI_LITE_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata2022.hdt
        WIKI_LITE_INDEX_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata2022.hdt.index.v1-1
        WIKI_CACHE_DB: http://files.deeppavlov.ai/kbqa/wikidata/wikidata_cache.json
        CONFIG: wiki_parser.json
        PORT: 8077
        SRC_DIR: annotators/wiki_parser
        COMMIT: ff5b156d16a949c3ec99da7fb60ae907dec37a41
        FAST: 1
      context: ./
      dockerfile: annotators/wiki_parser/Dockerfile
    command: flask run -h 0.0.0.0 -p 8077
    environment:
      - CUDA_VISIBLE_DEVICES=''
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  text-qa:
    env_file: [ .env ]
    build:
      args:
        CONFIG: qa.json
        PORT: 8078
        COMMIT: 4b3e60c407644b750c9dc292ac6bf206081fb9d0
      context: services/text_qa
      dockerfile: Dockerfile
    command: flask run -h 0.0.0.0 -p 8078
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  kbqa:
    env_file: [ .env ]
    build:
      args:
        CONFIG: kbqa_cq_mt_bert_lite.json
        PORT: 8072
        SRC_DIR: annotators/kbqa/
        COMMIT: 283a25e322e8fedc6ff0c159e4ec76bb165ae405
      context: ./
      dockerfile: annotators/kbqa/Dockerfile
    command: flask run -h 0.0.0.0 -p 8072
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 5G
        reservations:
          memory: 5G

  spelling-preprocessing:
    env_file: [ .env ]
    build:
      context: ./annotators/spelling_preprocessing/
    command: flask run -h 0.0.0.0 -p 8074
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 50M
        reservations:
          memory: 50M

  knowledge-grounding:
    env_file: [ .env ]
    build:
      args:
        MODEL_CKPT: 3_sent_62_epochs
        DATA_ARG: http://files.deeppavlov.ai/alexaprize_data/parlai_grounding_knowledge/parlai_topical_chat_data.tar.gz
        MODEL1_ARG: http://files.deeppavlov.ai/alexaprize_data/parlai_grounding_knowledge/topical_chat_blender90_1_sent_48_epochs.tar.gz
        MODEL2_ARG: http://files.deeppavlov.ai/alexaprize_data/parlai_grounding_knowledge/topical_chat_blender90_3_sent_62_epochs.tar.gz
      context: ./services/knowledge_grounding/
    command: flask run -h 0.0.0.0 -p 8083
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 4G

  dff-friendship-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8086
        SERVICE_NAME: dff_friendship_skill # has to be the same with skill dir name
      context: .
      dockerfile: ./skills/dff_friendship_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8086
    # command:  flask run -h 0.0.0.0 -p 8086
    # environment:
    #   - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  entity-storer:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: annotators/entity_storer/Dockerfile
      args:
        WORK_DIR: annotators/entity_storer
        SERVICE_PORT: 8089
    command: flask run -h 0.0.0.0 -p 8089
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 384M
        reservations:
          memory: 384M

  combined-classification:
    env_file: [ .env ]
    build:
      args:
        CONFIG: combined_classifier.json
        PORT: 8087
      context: .
      dockerfile: ./annotators/combined_classification/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  midas-classification:
    env_file: [ .env ]
    build:
      args:
        CONFIG: midas_conv_bert.json
      context: ./annotators/midas_classification
    command: flask run -h 0.0.0.0 -p 8090
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  fact-random:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8119
        SERVICE_NAME: fact_random
      context: .
      dockerfile: ./annotators/fact_random/Dockerfile
    command: flask run -h 0.0.0.0 -p 8119
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  fact-retrieval:
    env_file: [ .env ]
    build:
      args:
        CONFIG: configs/fact_retrieval_page.json
        CONFIG_WIKI: configs/page_extractor.json
        CONFIG_WHOW: configs/whow_page_extractor.json
        PORT: 8100
        SRC_DIR: annotators/fact_retrieval/
        COMMIT: 4b3e60c407644b750c9dc292ac6bf206081fb9d0
        N_FACTS: 3
      context: ./
      dockerfile: annotators/fact_retrieval/Dockerfile
    command: flask run -h 0.0.0.0 -p 8100
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 4G

  topic-recommendation:
    env_file: [ .env ]
    build:
      context: ./annotators/topic_recommendation/
    command: flask run -h 0.0.0.0 -p 8113
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  user-persona-extractor:
    env_file: [ .env ]
    build:
      context: .
      dockerfile: ./annotators/user_persona_extractor/Dockerfile
    command: flask run -h 0.0.0.0 -p 8114
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 80M
        reservations:
          memory: 80M

  wiki-facts:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8116
        SERVICE_NAME: wiki_facts
        CONFIG: page_extractor.json
        SRC_DIR: services/wiki_facts
        COMMIT: 5b99ac3392e8e178e2bb4f9b218d4ddb2ec2e242
      context: ./
      dockerfile: ./services/wiki_facts/Dockerfile
    command: flask run -h 0.0.0.0 -p 8116
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  entity-detection:
    env_file: [ .env ]
    build:
      args:
        SEQ_TAG_CONFIG: src/wikipedia_entity_detection_distilbert.json
        EL_TAG_CONFIG: src/el_tags_infer.json
        CONFIG: entity_detection_eng.json
        LOWERCASE: 1
        PORT: 8103
        SRC_DIR: annotators/entity_detection/
        FINEGRAINED: 0
      context: ./
      dockerfile: annotators/entity_detection/Dockerfile
    command: flask run -h 0.0.0.0 -p 8103
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 2.5G

  midas-predictor:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8121
        SERVICE_NAME: midas_predictor
      context: ./annotators/midas_predictor/
    command: flask run -h 0.0.0.0 -p 8121
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 50M
        reservations:
          memory: 50M

  relative-persona-extractor:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8133
        SERVICE_NAME: relative_persona_extractor
        N_SENTENCES_TO_RETURN: 3
      context: .
      dockerfile: ./annotators/relative_persona_extractor/Dockerfile
    command: flask run -h 0.0.0.0 -p 8133
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 80M
        reservations:
          memory: 80M

  sentence-ranker:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8128
        PRETRAINED_MODEL_NAME_OR_PATH: sentence-transformers/bert-base-nli-mean-tokens
      context: ./services/sentence_ranker/
    command: flask run -h 0.0.0.0 -p 8128
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 3G

  faq-skill:
    build:
      context: skills/faq_skill_deepy
    command: gunicorn --workers=1 server:app -b 0.0.0.0:3772 --timeout=1000
    ports:
      - 3710:3710

  dff-template-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8120
        SERVICE_NAME: dff_template_skill
      context: .
      dockerfile: ./skills/dff_template_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8120 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M
version: '3.7'
