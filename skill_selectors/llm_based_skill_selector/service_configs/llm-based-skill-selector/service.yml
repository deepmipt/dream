name: llm-based-skill-selector
endpoints:
- respond
compose:
  env_file: [ .env,.env_secret ]
  build:
    args:
      SERVICE_PORT: 8182
      SERVICE_NAME: skill_selector
      GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
      GENERATIVE_SERVICE_CONFIG: openai-chatgpt.json
      GENERATIVE_TIMEOUT: 20
      N_UTTERANCES_CONTEXT: 3
      ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION
      PROMPT_FILE: common/prompts/skill_selector.json
      MAX_N_SKILLS: 3
      FLASK_APP: server
    context: .
    dockerfile: ./skill_selectors/llm_based_skill_selector/Dockerfile
  command: flask run -h 0.0.0.0 -p 8182
  environment:
    - FLASK_APP=server
  deploy:
    resources:
      limits:
        memory: 100M
      reservations:
        memory: 100M
  ports:
  - 8182:8182
proxy: null

