toxic-classification-multilingual:
  name: toxic_classification
  display_name: Toxic Classification
  container_name: toxic-classification-multilingual
  model_type: NN-based
  is_customizable: false
  author: DeepPavlov
  description: 'classifies toxicity: identity_attack, insult, obscene, severe_toxicity,
    sexual_explicit, threat, toxicity'
  ram_usage: 3G
  gpu_usage: 2G
  execution_time: 2.0
  endpoints:
  - group: annotators
    port: 8013
    endpoint: respond
  - group: candidate_annotators
    port: 8013
    endpoint: respond_batch
  build_args:
    SERVICE_PORT: 8013
    SERVICE_NAME: toxic_classification
    PRETRAINED_MODEL_NAME_OR_PATH: https://github.com/unitaryai/detoxify/releases/download/v0.4-alpha/multilingual_debiased-0b549669.ckpt
  date_created: '2023-03-04T19:27:44'
